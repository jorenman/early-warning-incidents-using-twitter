{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing\n",
    "In this Jupyter Notebook, the initial dataset (tweets-31-05--06-06-2020.csv) will be preprocessed. This includes:\n",
    "* Importing of the data\n",
    "* Preprocessing of the data\n",
    "* Exporting the data to CSV and Pickle file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the data\n",
    "First, the data containing all the tweets will be imported.\n",
    "This dataset contains tweets between 31-05-2020 and 06-07-2021 with the word \"demonstratie\" in it (Dutch for \"demonstration\") in the Dutch language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary packages\n",
    "import pandas as pd\n",
    "import ast\n",
    "\n",
    "# Import the data and make sure that:\n",
    "# 'tweet_hashtags' column is a list\n",
    "data = pd.read_csv(\"~/Documents/Github Repository/early-warning-twitter/Original datasets/tweets-31-05--06-06-2020.csv\", converters={'hashtags':eval}, index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess the data\n",
    "Now, we will preprocess the data, so that we can use the final dataset for our analysis.\n",
    "\n",
    "The preprocessing of our data consists of three steps:\n",
    "* Converting the variables to the right data types\n",
    "* Automatically getting the mentioned users from tweets (in other Notebook the mentioned users will be labelled)\n",
    "* Adding a varibale that describes the type of user they mentioned \n",
    "* Preprocessing of text in tweets for text mining\n",
    "\n",
    "### Converting the variables to the right data types\n",
    "\n",
    "This will include:\n",
    "- Changing variables to the right data types\n",
    "- Transforming the hashtag objects to lists\n",
    "- Transforming the coordinate objects to lists\n",
    "- Transform the user determined Place (plain text) to a place name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading emoji data ...\n",
      "... OK (Got response in 0.37 seconds)\n",
      "Writing emoji data to /Users/jorenwouters/.demoji/codes.json ...\n",
      "... OK\n"
     ]
    }
   ],
   "source": [
    "# Import necessary packages\n",
    "import re\n",
    "import demoji\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Download demoji codes\n",
    "demoji.download_codes()\n",
    "\n",
    "# Create all the necessary functions that we need in this Jupyter Notebook\n",
    "\n",
    "# Function to clean the 'tweet_hashtags' column\n",
    "def clean_hashtag(row, variable):\n",
    "    # Get the hashtags of the row\n",
    "    hashtag = row[variable]\n",
    "    \n",
    "    if (hashtag != []) and (type(hashtag) != None):                             # Check if the tweet contains any hashtags\n",
    "        hashtag_list = []\n",
    "        for element in hashtag:\n",
    "            hashtag_list.append(element[\"text\"])  # Append every hashtag to a list\n",
    "        return hashtag_list\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# Function to clean the coordinates columns\n",
    "def clean_coordinates(row, variable):\n",
    "    import ast\n",
    "    \n",
    "    # Get the coordinates of the row\n",
    "    coordinate = row[variable]\n",
    "    \n",
    "    # Check if the coordinates has any value\n",
    "    if type(coordinate) == str:\n",
    "        coordinate = ast.literal_eval(coordinate)  # Change the string to a dictionary (so we can get the necessary elements)\n",
    "        i = 0\n",
    "        for element in coordinate:\n",
    "            if(i==0) :                             # This will skip the first element (not necessary)\n",
    "                i = i+1\n",
    "            else:\n",
    "                return coordinate['coordinates']   # Return only the coordinates\n",
    "    else:                                          # If the row is not a string it always is a nan, so we can set this to None\n",
    "        return None\n",
    "\n",
    "# Function to get only the place if tweet.place is acquired as a whole\n",
    "def clean_place(row, variable):\n",
    "    import pandas as pd\n",
    "    \n",
    "    # Get the place of the row\n",
    "    place = row[variable]\n",
    "\n",
    "    if not (pd.isnull(place)):\n",
    "        # Remove first unnecessary characters of the string\n",
    "        place = place[54:-1]\n",
    "\n",
    "        # Change = to :\n",
    "        place = place.replace('=', ':')\n",
    "\n",
    "        # Convert string to list, so we can delete elements\n",
    "        place = list(place.split(\",\")) \n",
    "\n",
    "        # Get the place name\n",
    "        place = place[3]\n",
    "        place = place.replace(':', ',')\n",
    "        place = list(place.split(\",\"))[1][1:-1]\n",
    "    \n",
    "        return place\n",
    "\n",
    "# Function to Get user mentions from tweet\n",
    "def get_user_mentions(row, variable):\n",
    "    import re\n",
    "    text = row[variable]\n",
    "    \n",
    "    # Regex to get the user mentions in a tweet\n",
    "    user_mentions = re.findall(\"(?<![@\\w])@(\\w{1,25})\", text)\n",
    "    \n",
    "    # If no user mentions do nothing, otherwise return list of user mentions\n",
    "    if user_mentions != []:\n",
    "        # Make all user mentions lowercase\n",
    "        for i in range(len(user_mentions)):\n",
    "            user_mentions[i] = user_mentions[i].lower()\n",
    "        return user_mentions\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "def var_to_lower(row, variable):\n",
    "    desc = row[variable].lower()\n",
    "    return desc\n",
    "\n",
    "# Clean the text of the tweet\n",
    "def clean_text(row, variable, hashtag_text='keep', representation = 'string'):\n",
    "    \n",
    "    # Parameters\n",
    "    # hashtag_text, default = 'keep'\n",
    "        # 'keep' - keeps the hashtag text and only removes the '#' in the text\n",
    "        # 'lose' - both removes the hashtag text and the '#' in the text\n",
    "    # representation, default = 'string'\n",
    "        # 'list' - returns a list of words\n",
    "        # 'string' - returns a sentence in string format\n",
    "    \n",
    "    tweet = row[variable]\n",
    "    \n",
    "    # Make the tweet lowercase\n",
    "    tweet = tweet.lower()\n",
    "    \n",
    "    # Remove words with less than two characters\n",
    "    tweet = re.sub(r'\\b\\w{1,2}\\b', '', tweet)\n",
    "    \n",
    "    # Remove URLs\n",
    "    tweet = remove_url(tweet)\n",
    "    \n",
    "    # Remove punctuations unless they are part of a digit (such as \"5.000\")\n",
    "    tweet = re.sub(r'(?:(?<!\\d)[.,;:…‘]|[.,;:…‘](?!\\d))', '', tweet)\n",
    "    \n",
    "    # Remove emojis\n",
    "    tweet = demoji.replace(tweet, \"\")\n",
    "    \n",
    "    if hashtag_text == 'keep':\n",
    "        tweet = tweet.replace(\"#\", \"\")\n",
    "        tweet = ' '.join(re.sub(\"(@[A-Za-z0-9]+)\", \"\", tweet).split())\n",
    "    else:\n",
    "        # Remove hashtags and mentions\n",
    "        tweet = ' '.join(re.sub(\"(@[A-Za-z0-9]+)|(#[A-Za-z0-9]+)\", \"\", tweet).split())\n",
    "    \n",
    "    # Remove non-alphanumeric charachters, line breaks and tabs\n",
    "    tweet = ' '.join(re.sub(\"([:/\\!@#$%^&*()_+{}[\\];\\\"”\\'|?<>~`\\-\\n\\t’])\", \"\", tweet).split())\n",
    "    \n",
    "    # Tokenize the tweet\n",
    "    tweet = word_tokenize(tweet)\n",
    "    \n",
    "    # Use Dutch stop words\n",
    "    stop_words = stopwords.words('dutch') + [\"rt\", \"nan\", \"NaN\"] \n",
    "    \n",
    "    # Remove stopwords\n",
    "    tweet = [w for w in tweet if not w in stop_words]\n",
    "    \n",
    "    if representation == 'list':\n",
    "        return tweet\n",
    "    else:\n",
    "        return listToString(tweet)\n",
    "\n",
    "# Function to convert a list to a string\n",
    "def listToString(s):  \n",
    "    \n",
    "    # initialize an empty string \n",
    "    str1 = \" \" \n",
    "    \n",
    "    # return string   \n",
    "    return (str1.join(s)) \n",
    "\n",
    "def remove_url(tweet_text):\n",
    "    if has_url_regex(tweet_text): \n",
    "        url_regex_list = regex_url_extractor(tweet_text)\n",
    "        for url in url_regex_list:\n",
    "            tweet_text = tweet_text.replace(url, \"\")\n",
    "    return tweet_text\n",
    "\n",
    "def has_url_regex(tweet_text):\n",
    "    return regex_url_extractor(tweet_text)\n",
    "\n",
    "def regex_url_extractor(tweet_text):\n",
    "    return re.findall('https?:\\/\\/(?:[-\\w\\/.]|(?:%[\\da-fA-F]{2}))+', tweet_text)\n",
    "\n",
    "def get_mentioned(row, variable):\n",
    "    user_mentions = row[variable]\n",
    "    list_mentioned = []\n",
    "    \n",
    "    # Check if tweet has mentioned_user\n",
    "    if (user_mentions != None) and (type(user_mentions) != float):\n",
    "        \n",
    "        # Make a list of user mentions (if it is a string)\n",
    "        if type(user_mentions) == str:\n",
    "            user_mentions = user_mentions.strip('][').split(', ') \n",
    "        \n",
    "        # For every user in user_mentions\n",
    "        for screen_name in user_mentions:\n",
    "            \n",
    "            # Remove single quotes from string\n",
    "            screen_name = screen_name.replace(\"'\", \"\")\n",
    "                        \n",
    "            # Check if we have information on this user            \n",
    "            if (labelled_users['screen_name'] == screen_name).any() == True:\n",
    "                \n",
    "                index = labelled_users[labelled_users['screen_name'] == screen_name].index[0]\n",
    "                mentioned_type = labelled_users.loc[index, 'type']\n",
    "                \n",
    "                # Check if the mentioned_type is not nan\n",
    "                if (type(mentioned_type) != float) and (mentioned_type != 'no type'):\n",
    "                    mentioned_type = mentioned_type.lower()\n",
    "                    list_mentioned.append(mentioned_type)\n",
    "                # If we have information on this user, determine what type of user it is\n",
    "                # Store type of user in the variable \"mentioned\"\n",
    "                #list_mentioned.append(   Hier moet dan ngo het soort gebruiker (moeten we ergens opvragen)   )\n",
    "                    \n",
    "    if list_mentioned != []:        \n",
    "        return list_mentioned\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def get_user_type(row, variable):\n",
    "    screen_name = row[variable]\n",
    "    list_mentioned = []\n",
    "    \n",
    "    # Check if tweet has screen_name \n",
    "    if (screen_name != None) and (type(screen_name) != float):\n",
    "            \n",
    "        # Remove single quotes from string\n",
    "        screen_name = screen_name.replace(\"'\", \"\")\n",
    "        \n",
    "        # Make screen_name lowercase\n",
    "        screen_name = screen_name.lower()\n",
    "                        \n",
    "        # Check if we have information on this user            \n",
    "        if (labelled_users['screen_name'] == screen_name).any() == True:\n",
    "                \n",
    "            index = labelled_users[labelled_users['screen_name'] == screen_name].index[0]\n",
    "            mentioned_type = labelled_users.loc[index, 'type']\n",
    "                \n",
    "            # Check if the mentioned_type is not nan\n",
    "            if (type(mentioned_type) != float) and (mentioned_type != 'no type'):\n",
    "                mentioned_type = mentioned_type.lower()\n",
    "                return mentioned_type  \n",
    "            else:\n",
    "                return None\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "# Function that checks if the tweet is a retweet (if this hasn't already been extracted from the Twitter API)\n",
    "def is_retweet(row, variable):\n",
    "    tweet = row[variable]\n",
    "    result = re.search(\"^(RT)\\s{1}\",tweet)\n",
    "    if result != None:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove duplicate tweets\n",
    "data = data.drop_duplicates('id')\n",
    "\n",
    "# Change columns to the right date types\n",
    "data[\"created_at\"] = pd.to_datetime(data[\"created_at\"])\n",
    "data[\"org_tweet_created_at\"] = pd.to_datetime(data[\"org_tweet_created_at\"])\n",
    "\n",
    "# Add 2 hours to created_at column\n",
    "# Original datetime is in UTC, but The Netherlands is in UTC+2\n",
    "data[\"created_at\"] = data[\"created_at\"] + pd.Timedelta(hours=2)\n",
    "data[\"org_tweet_created_at\"] = data[\"org_tweet_created_at\"] + pd.Timedelta(hours=2)\n",
    "\n",
    "# Get the month, day, hour and minute seperately of datetime\n",
    "data[\"month\"] = data[\"created_at\"].dt.month\n",
    "data[\"day\"] = data[\"created_at\"].dt.day\n",
    "data[\"hour\"] = data[\"created_at\"].dt.hour\n",
    "data[\"minute\"] = data[\"created_at\"].dt.minute\n",
    "\n",
    "# Only select the data that is on the 1st June 2020\n",
    "data = data[data[\"day\"]==1]\n",
    "\n",
    "# Apply clean_coordinates() to every row in tweet_coordinates column \n",
    "data[\"coordinates\"] = data.apply(clean_coordinates, args=([\"coordinates\"]), axis=1)\n",
    "\n",
    "# Apply clean_hashtag() to every row in tweet_hashtags column\n",
    "data[\"hashtags\"] = data.apply(clean_hashtag, args=([\"hashtags\"]), axis=1)\n",
    "\n",
    "# Apply clean_place() to every row in tweet_place column (only necessary if tweet.place is used as a whole)\n",
    "data[\"place\"] = data[\"place\"].astype('string')\n",
    "data[\"place\"] = data.apply(clean_place, args=([\"place\"]), axis=1) \n",
    "\n",
    "# Check if tweet is a retweet\n",
    "data[\"retweeted\"] = data.apply(is_retweet, args=([\"text\"]), axis=1)\n",
    "\n",
    "# We need a variable to count the number of cases in a certain time window\n",
    "data['count'] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Automatically getting the mentioned users from tweets\n",
    "Now, we will:\n",
    "* automatically get all the users that are mentioned in the tweets, and\n",
    "* determine the user type (based on an additional dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get user mentions from tweet\n",
    "data[\"user_mentions\"] = data.apply(get_user_mentions, args=([\"text\"]), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What type of mentioned user?\n",
    "The next we need to do is determine the type of user the Twitter user is.\n",
    "\n",
    "We do this by using a labelled user dataset created by using another Jupyter Notebook (Get user information from tweets) + manual labelling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dataset with labelled users\n",
    "# This must be a dataframe with two columns (screen_name and type)\n",
    "labelled_users = pd.read_pickle(\"~/Documents/Github Repository/early-warning-twitter/Processed datasets/Users/01-06-2020-amsterdam-demonstration-all-interesting-users-labelled.pkl\")\n",
    "\n",
    "data[\"user_mentions_types\"] = data.apply(get_mentioned, args=([\"user_mentions\"]), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What type of user that tweeted?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dataset with labelled users\n",
    "# This must be a dataframe with two columns (screen_name and type)\n",
    "labelled_users = pd.read_pickle(\"~/Documents/Github Repository/early-warning-twitter/Processed datasets/Users/01-06-2020-amsterdam-demonstration-all-interesting-users-labelled.pkl\")\n",
    "\n",
    "data[\"type_user\"] = data.apply(get_user_type, args=([\"user_screen_name\"]), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing for Text Mining\n",
    "\n",
    "Additionally, it is necessary to preprocess the text in the tweets, so that it can be analyzed for text mining."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"preprocessed_text\"] = data.apply(clean_text, args=([\"text\", 'keep', 'string']), axis=1)\n",
    "data[\"preprocessed_text_no_hashtag\"] = data.apply(clean_text, args=([\"text\", 'lose', 'string']), axis=1)\n",
    "data[\"preprocessed_text_tokenized\"] = data.apply(clean_text, args=([\"text\", 'keep', 'list']), axis=1)\n",
    "data[\"preprocessed_text_tokenized_no_hashtag\"] = data.apply(clean_text, args=([\"text\", 'lose', 'list']), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export datasets\n",
    "Now, we will export the different datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset the index\n",
    "data.reset_index(inplace=True, drop=True)\n",
    "\n",
    "# Export datasets in CSV and pickle file\n",
    "data.to_csv(\"~/Documents/Github Repository/early-warning-twitter/Processed datasets/Tweets/01-06-2020-amsterdam-demonstration.csv\")\n",
    "data.to_pickle(\"~/Documents/Github Repository/early-warning-twitter/Processed datasets/Tweets/01-06-2020-amsterdam-demonstration.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
