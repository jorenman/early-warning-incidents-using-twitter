{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing\n",
    "In this Jupyter Notebook, the unique tweets dataset (unique-labelled-tweets-01-06-2020.csv) will be preprocessed. This includes:\n",
    "* Importing of the data\n",
    "* Preprocessing of the data\n",
    "* Exporting the data to CSV and Pickle file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the data\n",
    "First, the data containing all the tweets will be imported.\n",
    "This dataset contains unique labelled tweets on 01-07-2020 with the word \"demonstratie\" in it (Dutch for \"demonstration\") in the Dutch language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary packages\n",
    "import pandas as pd\n",
    "\n",
    "# Import the data\n",
    "data = pd.read_csv(\"~/Documents/Github Repository/early-warning-twitter/Original datasets/unique-labelled-tweets-01-06-2020.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading emoji data ...\n",
      "... OK (Got response in 0.38 seconds)\n",
      "Writing emoji data to /Users/jorenwouters/.demoji/codes.json ...\n",
      "... OK\n"
     ]
    }
   ],
   "source": [
    "# Import necessary packages\n",
    "import re\n",
    "import demoji\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from urllib.parse import urlparse\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Download demoji codes\n",
    "demoji.download_codes()\n",
    "\n",
    "# Function to clean the coordinates columns\n",
    "def clean_coordinates(row, variable):\n",
    "    import ast\n",
    "    \n",
    "    # Get the coordinates of the row\n",
    "    coordinate = row[variable]\n",
    "    \n",
    "    # Check if the coordinates has any value\n",
    "    if type(coordinate) == str:\n",
    "        coordinate = ast.literal_eval(coordinate)  # Change the string to a dictionary (so we can get the necessary elements)\n",
    "        i = 0\n",
    "        for element in coordinate:\n",
    "            if(i==0) :                             # This will skip the first element (not necessary)\n",
    "                i = i+1\n",
    "            else:\n",
    "                return coordinate['coordinates']   # Return only the coordinates\n",
    "    else:                                          # If the row is not a string it always is a nan, so we can set this to None\n",
    "        return None\n",
    "    \n",
    "# Function that checks if the tweet is a retweet (based on the text)\n",
    "def is_retweet(tweet):\n",
    "    result = re.search(\"^(RT)\\s{1}\",tweet)\n",
    "    if result != None:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "# Function that cleans hashtag, user_mentions, urls and media fields\n",
    "def clean_field(row, variable, type_field):\n",
    "    field = row[variable]\n",
    "    \n",
    "    if (field != \"[]\") and (field != None):                              # Check if the field has any value\n",
    "        field_list = []\n",
    "        for element in field:\n",
    "            if (type_field == 'hashtag'):                   # Check if the field is hashtag field\n",
    "                field_list.append(element[\"text\"])\n",
    "            elif (type_field == 'user_mentions'):        # Check if the field is a user_mentions field\n",
    "                field_list.append(element[\"screen_name\"])\n",
    "            elif (type_field == 'urls'):\n",
    "                \n",
    "                # Check if the URL is from Twitter \n",
    "                # If it is from Twitter, do not add it to the list\n",
    "                url = element[\"expanded_url\"]\n",
    "                domain = domain = urlparse(url).netloc\n",
    "                if domain != \"twitter.com\":\n",
    "                    field_list.append(element[\"expanded_url\"])\n",
    "        \n",
    "        if field_list != []:\n",
    "            return field_list\n",
    "        else:\n",
    "            return None\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "# Function that takes the media in a tweet and it takes the thumbnails (if a website page is shared)\n",
    "# And stores those values in the variable \"cleaned_media\"\n",
    "def clean_media(data):\n",
    "    media_df = pd.DataFrame(columns=[\"url\", \"thumbnail_url\"])\n",
    "    o = 0\n",
    "    \n",
    "    for i in range(len(data)):\n",
    "        media = data.loc[i, 'media']\n",
    "        urls = data.loc[i, 'urls']\n",
    "        media_list = []\n",
    "        \n",
    "        # If there is media in the tweet, append the media_url to media_list\n",
    "        if (media != \"[]\") and (media != None):\n",
    "            for element in media:\n",
    "                media_list.append(element[\"media_url\"])\n",
    "                \n",
    "        if(urls != None):\n",
    "            for url in urls:\n",
    "        \n",
    "                # If the URL is already handled, get the thumbnail_url from the DataFrame\n",
    "                if (media_df[\"url\"]==url).any() == True:\n",
    "                    index = media_df[media_df[\"url\"]==url].index.values.astype(int)[0]\n",
    "                    thumbnail = media_df.loc[index, 'thumbnail_url']\n",
    "\n",
    "                # Otherwise make a request to the URL\n",
    "                else:\n",
    "\n",
    "                    try:\n",
    "\n",
    "                        # Make a request to the URL\n",
    "                        reqs = requests.get(url)\n",
    "\n",
    "                        # Get the HTML of the URL\n",
    "                        soup = BeautifulSoup(reqs.text, 'html.parser')\n",
    "\n",
    "                        # Get the thumbnail of the web page\n",
    "                        thumbnail = soup.find('meta', property=\"og:image\")\n",
    "\n",
    "                        # Check if there is a thumbnail. If there is, grab the thumbnail URL\n",
    "                        if(thumbnail != None):\n",
    "                            thumbnail = thumbnail['content']\n",
    "                            \n",
    "                            # Store the URL and thumbnail url in the DataFrame\n",
    "                            media_df.loc[o, 'url'] = url\n",
    "                            media_df.loc[o, 'thumbnail_url'] = thumbnail\n",
    "\n",
    "                            o = o+1\n",
    "                    except:\n",
    "                        pass\n",
    "                \n",
    "                # If there is a thumbnail, add it to the media list\n",
    "                if(thumbnail):\n",
    "                    media_list.append(thumbnail)\n",
    "        \n",
    "        # If we have media in the media_list, use it. Otherwise set it to None\n",
    "        if(media_list != []):\n",
    "            data[\"cleaned_media\"][i] = media_list\n",
    "        else:\n",
    "            data[\"cleaned_media\"][i] = None\n",
    "    \n",
    "# Function to get the number of words in a tweet\n",
    "def get_n_words(row, variable):\n",
    "    tweet = row[variable]\n",
    "    return len(re.findall(r'\\w+', tweet)) \n",
    "\n",
    "# Function to get the number of characters in a tweet\n",
    "def get_n_characters(row,variable):\n",
    "    tweet = row[variable]\n",
    "    return len(tweet)\n",
    "\n",
    "def get_user_type(row, variable):\n",
    "    screen_name = row[variable]\n",
    "    list_mentioned = []\n",
    "    \n",
    "    # Check if tweet has screen_name \n",
    "    if (screen_name != None) and (type(screen_name) != float):\n",
    "            \n",
    "        # Remove single quotes from string\n",
    "        screen_name = screen_name.replace(\"'\", \"\")\n",
    "        \n",
    "        # Make screen_name lowercase\n",
    "        screen_name = screen_name.lower()\n",
    "                        \n",
    "        # Check if we have information on this user            \n",
    "        if (labelled_users['screen_name'] == screen_name).any() == True:\n",
    "                \n",
    "            index = labelled_users[labelled_users['screen_name'] == screen_name].index[0]\n",
    "            mentioned_type = labelled_users.loc[index, 'type']\n",
    "                \n",
    "            # Check if the mentioned_type is not nan\n",
    "            if type(mentioned_type) != float:\n",
    "                mentioned_type = mentioned_type.lower()\n",
    "                return mentioned_type  \n",
    "            else:\n",
    "                return None\n",
    "        else:\n",
    "            return None\n",
    "    \n",
    "        \n",
    "# A function that takes the full_text variable and the title of a web page (if a web page is shared)\n",
    "# Stores those text data in one variable\n",
    "# And then cleans that variable using the clean_text() function\n",
    "def clean_full_text(data):\n",
    "    urls_df_text = pd.DataFrame(columns=[\"url\", \"title_url\"])\n",
    "    o = 0\n",
    "\n",
    "    for i in range(len(data)):\n",
    "        text = data.loc[i, 'full_text']\n",
    "        urls = data.loc[i, 'urls']\n",
    "\n",
    "        if(urls != None):\n",
    "            for url in urls:\n",
    "\n",
    "                # If the URL is already handled, get the title from the DataFrame\n",
    "                if (urls_df_text[\"url\"]==url).any() == True:\n",
    "                    index = urls_df_text[urls_df_text[\"url\"]==url].index.values.astype(int)[0]\n",
    "                    title = urls_df_text.loc[index, 'title_url']\n",
    "\n",
    "                # This URL has a cookie gate\n",
    "                elif url == \"https://www.ad.nl/den-haag/me-grijpt-in-bij-lockdownprotest-den-haag-37-arrestaties~a4e031d0/\":\n",
    "                    title = \"ME grijpt in bij lockdownprotest Den Haag: 37 arrestaties\"\n",
    "\n",
    "                # This URL has a cookie gate\n",
    "                elif url == \"https://www.ad.nl/amsterdam/maandag-demonstratie-op-de-dam-tegen-politiegeweld-in-amerika~a3c63f8f/\":\n",
    "                    title = \"Maandag demonstratie op de Dam tegen politiegeweld in Amerika\"\n",
    "\n",
    "                # This URL has a cookie gate\n",
    "                elif (url == \"http://ad.nl\") or (url == \"http://AD.nl\"):\n",
    "                    title = \"AD.nl, het laatste nieuws uit binnen- en buitenland, sport en show\"\n",
    "\n",
    "                # This URL has a cookie gate\n",
    "                elif (url == \"https://www.ad.nl/dossier-instagram/dam-in-amsterdam-bomvol-met-duizenden-demonstranten-tegen-politiegeweld~aae7b3e9/?utm_source=twitter&utm_medium=social&utm_campaign=socialsharing_web\") or (url == \"https://www.ad.nl/dossier-instagram/duizenden-demonstranten-tegen-politiegeweld-dam-in-amsterdam-bomvol~aae7b3e9/?utm_source=twitter&utm_medium=social&utm_campaign=socialsharing_web\") or (url == \"https://www.gelderlander.nl/binnenland/duizenden-demonstranten-tegen-politiegeweld-dam-in-amsterdam-bomvol~aae7b3e9/\") or (url==\"https://www.ad.nl/binnenland/duizenden-demonstranten-tegen-politiegeweld-dam-in-amsterdam-bomvol~aae7b3e9/\") or (url==\"https://www.ad.nl/binnenland/dam-in-amsterdam-bomvol-met-duizenden-demonstranten-tegen-politiegeweld~aae7b3e9/\") or (url==\"https://www.pzc.nl/binnenland/dam-in-amsterdam-bomvol-met-duizenden-demonstranten-tegen-politiegeweld~aae7b3e9/\") or (url==\"https://www.ad.nl/binnenland/dam-in-amsterdam-bomvol-met-demonstranten-tegen-politiegeweld~aae7b3e9/\"):\n",
    "                    title = \"Duizenden demonstranten tegen politiegeweld: Dam in Amsterdam bomvol\"\n",
    "\n",
    "                # This URL has a cookie gate\n",
    "                elif (url == \"https://www.ad.nl/binnenland/onbegrip-in-tweede-kamer-over-drukte-bij-racismebetoging-klap-in-gezicht-zorgverleners~addcbdf2/\") or (url==\"https://www.ad.nl/binnenland/massademonstratie-wekt-woede-dit-is-klap-in-gezicht~addcbdf2/?utm_source=twitter&utm_medium=social&utm_campaign=socialsharing_web\"):\n",
    "                    title = \"Massademonstratie wekt woede: ‘Dit is klap in gezicht’\"\n",
    "\n",
    "                # This URL has a cookie gate\n",
    "                elif (url == \"https://www.ad.nl/dossier-instagram-ad-haagsche-courant/tachtig-anti-lockdownactivisten-aangehouden-bij-demonstratie-in-den-haag~aa966a30/?utm_source=twitter&utm_medium=social&utm_campaign=socialsharing_web\"):\n",
    "                    title = \"Tachtig anti-lockdownactivisten aangehouden bij demonstratie in Den Haag\"\n",
    "\n",
    "                # This URL has a cookie gate\n",
    "                elif (url==\"https://www.geenstijl.nl/5153730/positie-halsema-onder-vuur-na-negeren-regels/\"):\n",
    "                    title = \"Positie Halsema onder vuur na negeren regels\"\n",
    "\n",
    "                # This URL has a cookie gate\n",
    "                elif (url==\"https://youtu.be/R2JSFO0HeX8\"):\n",
    "                    title = \"Demonstratie tegen de Lock Down en de anderhalve meter maatschappij!\"\n",
    "\n",
    "                # This URL has a cookie gate\n",
    "                elif url == \"http://ad.nl/rotterdam/vvd-amsterdamse-toestanden-voorkomen-bij-demonstratie-kozp-op-schouwburgplein~ab72c30a/\":\n",
    "                    title = \"VVD: Amsterdamse toestanden voorkomen bij demonstratie KOZP op Schouwburgplein\"\n",
    "\n",
    "                # This URL has a cookie gate\n",
    "                elif url == \"https://www.destentor.nl/dossier-coronavirus/geen-laatste-afscheid-voor-echtpaar-door-getouwtrek-rond-coronaregels-bij-woonzorgcentrum~a68908c9/?utm_source=twitter&utm_medium=social&utm_campaign=socialsharing_web\":\n",
    "                    title = \"Geen laatste afscheid voor echtpaar door getouwtrek rond coronaregels bij woonzorgcentrum\"\n",
    "\n",
    "                # This URL has a cookie gate\n",
    "                elif url == \"https://www.ad.nl/binnenland/burgemeester-halsema-vindt-een-politiek-standpunt-belangrijker-dan-mensenlevens~ae5f8e1f6/\":\n",
    "                    title = \"Burgemeester Halsema vindt een politiek standpunt belangrijker dan mensenlevens\"\n",
    "\n",
    "                # These URLs doesn't have a video anymore\n",
    "                elif (url == \"https://youtube.com/watch?v=WFI0WNHHImo&feature=share&app=desktop\") or (url == \"https://youtu.be/rZ_DSCKwLFA\") or (url == \"https://youtu.be/Ww2YzlM1_Dk\") or (url == \"https://www.youtube.com/watch?v=KGEekP1102g\") or (url==\"https://youtu.be/w8D40uv9Wy0\"):\n",
    "                    title = None\n",
    "\n",
    "                # URL with 500 error\n",
    "                elif (url == \"https://bit.ly/2zMG2EM\"):\n",
    "                    title = None\n",
    "\n",
    "                # Facebook doesn't provide titles for posts\n",
    "                elif (url == \"https://www.facebook.com/1576224044/posts/10220303674493439/?app=fbl\") or (url==\"https://www.facebook.com/KOZPDenHaag/photos/a.103964200996568/292254242167562/?type=3&theater\"):\n",
    "                    title = None\n",
    "\n",
    "                # These URLs are not external URLs\n",
    "                elif (url == \"https://Twitter.com/kareldoorman3/\") or (url == \"https://t.co/VX1a8WaIUM\") or (url==\"https://t.co/lQND3Q2SPk\") or (url==\"https://t.co/QgcHFjZmdA\") or (url==\"https://mobile.twitter.com/fvdemocratie/status/1267407150172831745\") or (url==\"https://t.co/HtWh2JswA3\") or (url==\"https://bit.ly/2zHG5SA\"):\n",
    "                    title = None\n",
    "\n",
    "                # These are not Dutch websites, don't take it into account\n",
    "                elif (url == \"https://www.npr.org/2020/05/31/866428272/george-floyd-reverberates-globally-thousands-protest-in-germany-u-k-canada\") or (url == \"https://popculture.com/trending/news/man-beaten-after-chasing-protesters-sword-twitter-weighs-in/\") or (url == \"https://support.twitter.com/articles/20169199\") or (url == \"https://www.knowyourrightscamp.com/\") or (url == \"https://www.independent.co.uk/sport/football/european/coronavirus-news-latest-atalanta-valencia-champions-league-italy-crisis-bergamo-a9448541.html\") or (url == \"http://Halsema.De\") or (url==\"https://www.facebook.com/events/283690002806623/\") or (url==\"https://facebook.com/events/283690002806623/\") or (url==\"https://docs.google.com/document/d/1BRlF2_zhNe86SGgHa6-VlBO-QgirITwCTugSfKie5Fs/mobilebasic\") or (url==\"https://wapo.st/2AqMiCn\") or (url==\"http://g1.globo.com/globo-news/protestos-no-brasil/videos/t/todos-os-videos/v/policial-aponta-fuzil-para-manifestante-no-rio-de-janeiro/8592982\") or (url==\"https://www.google.com/amp/s/amp.theguardian.com/world/2020/may/20/black-americans-death-rate-covid-19-coronavirus\"):\n",
    "                    title = None\n",
    "\n",
    "                # Otherwise make a request to the URL\n",
    "                else:\n",
    "                    # Make a request to the URL\n",
    "                    # reqs = requests.get(url)\n",
    "\n",
    "                    try:\n",
    "                        reqs = requests.get(url)\n",
    "\n",
    "                        # Get the HTML of the URL\n",
    "                        soup = BeautifulSoup(reqs.text, 'html.parser')\n",
    "\n",
    "                        # Get the title of the web page\n",
    "                        title= soup.find_all('title')\n",
    "\n",
    "                        # Get the title of the web page as a string\n",
    "                        if type(title) == str:\n",
    "                            title = title.get_text()\n",
    "                        elif (title != None) and (title != []):\n",
    "                            title = title[0].get_text()\n",
    "\n",
    "                        if (\"Pagina niet gevonden\" in title) or (\"Aanmelden bij Facebook\" in title) or (\"Not Found\" in title) or (\"Pagina bestaat niet meer\" in title):\n",
    "                            title = None\n",
    "\n",
    "                        # Store the URL and title in the DataFrame\n",
    "                        urls_df_text.loc[o, 'url'] = url\n",
    "                        urls_df_text.loc[o, 'title_url'] = title\n",
    "\n",
    "                        o = o+1\n",
    "                    except:\n",
    "                        pass\n",
    "\n",
    "                if(title):\n",
    "                    text = text + \" \" + str(title)\n",
    "                else:\n",
    "                    text = data.loc[i, 'full_text']\n",
    "\n",
    "        data[\"preprocessed_text\"][i] = clean_text(text, 'keep', 'string')\n",
    "        data[\"preprocessed_text_no_hashtag\"][i] = clean_text(text, 'lose', 'string')\n",
    "        data[\"preprocessed_text_tokenized\"][i] = clean_text(text, 'keep', 'list')\n",
    "        data[\"preprocessed_text_tokenized_no_hashtag\"][i] = clean_text(text, 'lose', 'list')\n",
    "        \n",
    "# A function that takes the full_text variable and the title of a web page (if a web page is shared)\n",
    "# Stores those text data in one variable\n",
    "# And then cleans that variable using the clean_text_partly() function\n",
    "def clean_full_text_partly(data):\n",
    "    urls_df_text = pd.DataFrame(columns=[\"url\", \"title_url\"])\n",
    "    o = 0\n",
    "\n",
    "    for i in range(len(data)):\n",
    "        text = data.loc[i, 'full_text']\n",
    "        urls = data.loc[i, 'urls']\n",
    "\n",
    "        if(urls != None):\n",
    "            for url in urls:\n",
    "\n",
    "                # If the URL is already handled, get the title from the DataFrame\n",
    "                if (urls_df_text[\"url\"]==url).any() == True:\n",
    "                    index = urls_df_text[urls_df_text[\"url\"]==url].index.values.astype(int)[0]\n",
    "                    title = urls_df_text.loc[index, 'title_url']\n",
    "\n",
    "                # This URL has a cookie gate\n",
    "                elif url == \"https://www.ad.nl/den-haag/me-grijpt-in-bij-lockdownprotest-den-haag-37-arrestaties~a4e031d0/\":\n",
    "                    title = \"ME grijpt in bij lockdownprotest Den Haag: 37 arrestaties\"\n",
    "\n",
    "                # This URL has a cookie gate\n",
    "                elif url == \"https://www.ad.nl/amsterdam/maandag-demonstratie-op-de-dam-tegen-politiegeweld-in-amerika~a3c63f8f/\":\n",
    "                    title = \"Maandag demonstratie op de Dam tegen politiegeweld in Amerika\"\n",
    "\n",
    "                # This URL has a cookie gate\n",
    "                elif (url == \"http://ad.nl\") or (url == \"http://AD.nl\"):\n",
    "                    title = \"AD.nl, het laatste nieuws uit binnen- en buitenland, sport en show\"\n",
    "\n",
    "                # This URL has a cookie gate\n",
    "                elif (url == \"https://www.ad.nl/dossier-instagram/dam-in-amsterdam-bomvol-met-duizenden-demonstranten-tegen-politiegeweld~aae7b3e9/?utm_source=twitter&utm_medium=social&utm_campaign=socialsharing_web\") or (url == \"https://www.ad.nl/dossier-instagram/duizenden-demonstranten-tegen-politiegeweld-dam-in-amsterdam-bomvol~aae7b3e9/?utm_source=twitter&utm_medium=social&utm_campaign=socialsharing_web\") or (url == \"https://www.gelderlander.nl/binnenland/duizenden-demonstranten-tegen-politiegeweld-dam-in-amsterdam-bomvol~aae7b3e9/\") or (url==\"https://www.ad.nl/binnenland/duizenden-demonstranten-tegen-politiegeweld-dam-in-amsterdam-bomvol~aae7b3e9/\") or (url==\"https://www.ad.nl/binnenland/dam-in-amsterdam-bomvol-met-duizenden-demonstranten-tegen-politiegeweld~aae7b3e9/\") or (url==\"https://www.pzc.nl/binnenland/dam-in-amsterdam-bomvol-met-duizenden-demonstranten-tegen-politiegeweld~aae7b3e9/\") or (url==\"https://www.ad.nl/binnenland/dam-in-amsterdam-bomvol-met-demonstranten-tegen-politiegeweld~aae7b3e9/\"):\n",
    "                    title = \"Duizenden demonstranten tegen politiegeweld: Dam in Amsterdam bomvol\"\n",
    "\n",
    "                # This URL has a cookie gate\n",
    "                elif (url == \"https://www.ad.nl/binnenland/onbegrip-in-tweede-kamer-over-drukte-bij-racismebetoging-klap-in-gezicht-zorgverleners~addcbdf2/\") or (url==\"https://www.ad.nl/binnenland/massademonstratie-wekt-woede-dit-is-klap-in-gezicht~addcbdf2/?utm_source=twitter&utm_medium=social&utm_campaign=socialsharing_web\"):\n",
    "                    title = \"Massademonstratie wekt woede: ‘Dit is klap in gezicht’\"\n",
    "\n",
    "                # This URL has a cookie gate\n",
    "                elif (url == \"https://www.ad.nl/dossier-instagram-ad-haagsche-courant/tachtig-anti-lockdownactivisten-aangehouden-bij-demonstratie-in-den-haag~aa966a30/?utm_source=twitter&utm_medium=social&utm_campaign=socialsharing_web\"):\n",
    "                    title = \"Tachtig anti-lockdownactivisten aangehouden bij demonstratie in Den Haag\"\n",
    "\n",
    "                # This URL has a cookie gate\n",
    "                elif (url==\"https://www.geenstijl.nl/5153730/positie-halsema-onder-vuur-na-negeren-regels/\"):\n",
    "                    title = \"Positie Halsema onder vuur na negeren regels\"\n",
    "\n",
    "                # This URL has a cookie gate\n",
    "                elif (url==\"https://youtu.be/R2JSFO0HeX8\"):\n",
    "                    title = \"Demonstratie tegen de Lock Down en de anderhalve meter maatschappij!\"\n",
    "\n",
    "                # This URL has a cookie gate\n",
    "                elif url == \"http://ad.nl/rotterdam/vvd-amsterdamse-toestanden-voorkomen-bij-demonstratie-kozp-op-schouwburgplein~ab72c30a/\":\n",
    "                    title = \"VVD: Amsterdamse toestanden voorkomen bij demonstratie KOZP op Schouwburgplein\"\n",
    "\n",
    "                # This URL has a cookie gate\n",
    "                elif url == \"https://www.destentor.nl/dossier-coronavirus/geen-laatste-afscheid-voor-echtpaar-door-getouwtrek-rond-coronaregels-bij-woonzorgcentrum~a68908c9/?utm_source=twitter&utm_medium=social&utm_campaign=socialsharing_web\":\n",
    "                    title = \"Geen laatste afscheid voor echtpaar door getouwtrek rond coronaregels bij woonzorgcentrum\"\n",
    "\n",
    "                # This URL has a cookie gate\n",
    "                elif url == \"https://www.ad.nl/binnenland/burgemeester-halsema-vindt-een-politiek-standpunt-belangrijker-dan-mensenlevens~ae5f8e1f6/\":\n",
    "                    title = \"Burgemeester Halsema vindt een politiek standpunt belangrijker dan mensenlevens\"\n",
    "\n",
    "                # These URLs doesn't have a video anymore\n",
    "                elif (url == \"https://youtube.com/watch?v=WFI0WNHHImo&feature=share&app=desktop\") or (url == \"https://youtu.be/rZ_DSCKwLFA\") or (url == \"https://youtu.be/Ww2YzlM1_Dk\") or (url == \"https://www.youtube.com/watch?v=KGEekP1102g\") or (url==\"https://youtu.be/w8D40uv9Wy0\"):\n",
    "                    title = None\n",
    "\n",
    "                # URL with 500 error\n",
    "                elif (url == \"https://bit.ly/2zMG2EM\"):\n",
    "                    title = None\n",
    "\n",
    "                # Facebook doesn't provide titles for posts\n",
    "                elif (url == \"https://www.facebook.com/1576224044/posts/10220303674493439/?app=fbl\") or (url==\"https://www.facebook.com/KOZPDenHaag/photos/a.103964200996568/292254242167562/?type=3&theater\"):\n",
    "                    title = None\n",
    "\n",
    "                # These URLs are not external URLs\n",
    "                elif (url == \"https://Twitter.com/kareldoorman3/\") or (url == \"https://t.co/VX1a8WaIUM\") or (url==\"https://t.co/lQND3Q2SPk\") or (url==\"https://t.co/QgcHFjZmdA\") or (url==\"https://mobile.twitter.com/fvdemocratie/status/1267407150172831745\") or (url==\"https://t.co/HtWh2JswA3\") or (url==\"https://bit.ly/2zHG5SA\"):\n",
    "                    title = None\n",
    "\n",
    "                # These are not Dutch websites, don't take it into account\n",
    "                elif (url == \"https://www.npr.org/2020/05/31/866428272/george-floyd-reverberates-globally-thousands-protest-in-germany-u-k-canada\") or (url == \"https://popculture.com/trending/news/man-beaten-after-chasing-protesters-sword-twitter-weighs-in/\") or (url == \"https://support.twitter.com/articles/20169199\") or (url == \"https://www.knowyourrightscamp.com/\") or (url == \"https://www.independent.co.uk/sport/football/european/coronavirus-news-latest-atalanta-valencia-champions-league-italy-crisis-bergamo-a9448541.html\") or (url == \"http://Halsema.De\") or (url==\"https://www.facebook.com/events/283690002806623/\") or (url==\"https://facebook.com/events/283690002806623/\") or (url==\"https://docs.google.com/document/d/1BRlF2_zhNe86SGgHa6-VlBO-QgirITwCTugSfKie5Fs/mobilebasic\") or (url==\"https://wapo.st/2AqMiCn\") or (url==\"http://g1.globo.com/globo-news/protestos-no-brasil/videos/t/todos-os-videos/v/policial-aponta-fuzil-para-manifestante-no-rio-de-janeiro/8592982\") or (url==\"https://www.google.com/amp/s/amp.theguardian.com/world/2020/may/20/black-americans-death-rate-covid-19-coronavirus\"):\n",
    "                    title = None\n",
    "\n",
    "                # Otherwise make a request to the URL\n",
    "                else:\n",
    "                    # Make a request to the URL\n",
    "                    # reqs = requests.get(url)\n",
    "\n",
    "                    try:\n",
    "                        reqs = requests.get(url)\n",
    "\n",
    "                        # Get the HTML of the URL\n",
    "                        soup = BeautifulSoup(reqs.text, 'html.parser')\n",
    "\n",
    "                        # Get the title of the web page\n",
    "                        title= soup.find_all('title')\n",
    "\n",
    "                        # Get the title of the web page as a string\n",
    "                        if type(title) == str:\n",
    "                            title = title.get_text()\n",
    "                        elif (title != None) and (title != []):\n",
    "                            title = title[0].get_text()\n",
    "\n",
    "                        if (\"Pagina niet gevonden\" in title) or (\"Aanmelden bij Facebook\" in title) or (\"Not Found\" in title) or (\"Pagina bestaat niet meer\" in title):\n",
    "                            title = None\n",
    "\n",
    "                        # Store the URL and title in the DataFrame\n",
    "                        urls_df_text.loc[o, 'url'] = url\n",
    "                        urls_df_text.loc[o, 'title_url'] = title\n",
    "\n",
    "                        o = o+1\n",
    "                    except:\n",
    "                        pass\n",
    "\n",
    "                if(title):\n",
    "                    text = text + \" \" + str(title)\n",
    "                else:\n",
    "                    text = data.loc[i, 'full_text']\n",
    "\n",
    "        data[\"preprocessed_text_partly\"][i] = clean_text_partly(text)\n",
    "        \n",
    "# Clean the text of the tweet\n",
    "def clean_text(text, hashtag_text='keep', representation = 'string'):\n",
    "    \n",
    "    # Parameters\n",
    "    # hashtag_text, default = 'keep'\n",
    "        # 'keep' - keeps the hashtag text and only removes the '#' in the text\n",
    "        # 'lose' - both removes the hashtag text and the '#' in the text\n",
    "    # representation, default = 'string'\n",
    "        # 'list' - returns a list of words\n",
    "        # 'string' - returns a sentence in string format\n",
    "    \n",
    "    tweet = text\n",
    "    \n",
    "    # Make the tweet lowercase\n",
    "    tweet = tweet.lower()\n",
    "    \n",
    "    # Remove words with less than two characters\n",
    "    tweet = re.sub(r'\\b\\w{1,2}\\b', '', tweet)\n",
    "    \n",
    "    # Remove URLs\n",
    "    tweet = remove_url(tweet)\n",
    "    \n",
    "    # Remove punctuations unless they are part of a digit (such as \"5.000\")\n",
    "    tweet = re.sub(r'(?:(?<!\\d)[.,;:…‘]|[.,;:…‘](?!\\d))', '', tweet)\n",
    "    \n",
    "    # Remove emojis\n",
    "    tweet = demoji.replace(tweet, \"\")\n",
    "    \n",
    "    if hashtag_text == 'keep':\n",
    "        tweet = tweet.replace(\"#\", \"\")\n",
    "        # Remove mentions (also the text after the @)\n",
    "        tweet = ' '.join(re.sub(\"(@[A-Za-z0-9]+)\", \"\", tweet).split())\n",
    "    else:\n",
    "        # Remove hashtags and mentions (also the text after the # and @)\n",
    "        tweet = ' '.join(re.sub(\"(@[A-Za-z0-9]+)|(#[A-Za-z0-9]+)\", \"\", tweet).split())\n",
    "    \n",
    "    # Remove non-alphanumeric charachters, line breaks and tabs\n",
    "    tweet = ' '.join(re.sub(\"([:/\\!@#$%^&*()_+{}[\\];\\\"”\\'|?<>~`\\-\\n\\t’])\", \"\", tweet).split())\n",
    "    \n",
    "    # Tokenize the tweet\n",
    "    tweet = word_tokenize(tweet)\n",
    "    \n",
    "    # Use Dutch stop words\n",
    "    stop_words = stopwords.words('dutch') + [\"rt\", \"nan\", \"NaN\"] \n",
    "    \n",
    "    # Remove stopwords\n",
    "    tweet = [w for w in tweet if not w in stop_words]\n",
    "    \n",
    "    if representation == 'list':\n",
    "        return tweet\n",
    "    else:\n",
    "        return listToString(tweet)\n",
    "\n",
    "# Function that partly cleans the text of a tweet\n",
    "def clean_text_partly(text):\n",
    "    \n",
    "    tweet = text\n",
    "    \n",
    "    # Make the tweet lowercase\n",
    "    tweet = tweet.lower()\n",
    "    \n",
    "    # Remove URLs\n",
    "    tweet = remove_url(tweet)\n",
    "    \n",
    "    # Remove emojis\n",
    "    tweet = demoji.replace(tweet, \"\")\n",
    "    \n",
    "    # Remove mentions (also the text after the @)\n",
    "    tweet = ' '.join(re.sub(\"(@[A-Za-z0-9]+)\", \"\", tweet).split())\n",
    "    \n",
    "    # Remove non-alphanumeric charachters, line breaks and tabs\n",
    "    tweet = ' '.join(re.sub(\"([:/\\!@$%^&*()_+{}[\\];\\\"”\\'|?<>~`\\\\n\\t’])\", \"\", tweet).split())\n",
    "    \n",
    "    return tweet;\n",
    "    \n",
    "# Function to convert a list to a string\n",
    "def listToString(s):  \n",
    "    \n",
    "    # initialize an empty string \n",
    "    str1 = \" \" \n",
    "    \n",
    "    # return string   \n",
    "    return (str1.join(s)) \n",
    "    \n",
    "def remove_url(tweet_text):\n",
    "    if has_url_regex(tweet_text): \n",
    "        url_regex_list = regex_url_extractor(tweet_text)\n",
    "        for url in url_regex_list:\n",
    "            tweet_text = tweet_text.replace(url, \"\")\n",
    "    return tweet_text\n",
    "\n",
    "def has_url_regex(tweet_text):\n",
    "    return regex_url_extractor(tweet_text)\n",
    "\n",
    "def regex_url_extractor(tweet_text):\n",
    "    return re.findall('https?:\\/\\/(?:[-\\w\\/.]|(?:%[\\da-fA-F]{2}))+', tweet_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-27b99c7a98f9>:50: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[\"hashtags\"][i] = entities_dict.get(\"hashtags\")\n",
      "<ipython-input-10-27b99c7a98f9>:51: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[\"user_mentions\"][i] = entities_dict.get(\"user_mentions\")\n",
      "<ipython-input-10-27b99c7a98f9>:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[\"urls\"][i] = entities_dict.get(\"urls\")\n",
      "<ipython-input-10-27b99c7a98f9>:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[\"media\"][i] = entities_dict.get(\"media\")\n",
      "<ipython-input-8-37696e30125f>:136: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[\"cleaned_media\"][i] = media_list\n",
      "<ipython-input-8-37696e30125f>:138: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[\"cleaned_media\"][i] = None\n"
     ]
    }
   ],
   "source": [
    "import json5\n",
    "\n",
    "# Remove duplicate tweets\n",
    "data = data.drop_duplicates('id')\n",
    "\n",
    "# Change columns to the right date types\n",
    "data[\"created_at\"] = pd.to_datetime(data[\"created_at\"])\n",
    "data[\"org_tweet_created_at\"] = pd.to_datetime(data[\"org_tweet_created_at\"])\n",
    "\n",
    "# Add 2 hours to created_at column\n",
    "# Original datetime is in UTC, but The Netherlands is in UTC+2\n",
    "data[\"created_at\"] = data[\"created_at\"] + pd.Timedelta(hours=2)\n",
    "data[\"org_tweet_created_at\"] = data[\"org_tweet_created_at\"] + pd.Timedelta(hours=2)\n",
    "\n",
    "# Get the month, day, hour and minute seperately of datetime\n",
    "data[\"month\"] = data[\"created_at\"].dt.month\n",
    "data[\"day\"] = data[\"created_at\"].dt.day\n",
    "data[\"hour\"] = data[\"created_at\"].dt.hour\n",
    "data[\"minute\"] = data[\"created_at\"].dt.minute\n",
    "\n",
    "# Only select the data that is on the 1st June 2020\n",
    "data = data[(data[\"day\"]==1)&(data[\"month\"]==6)]\n",
    "\n",
    "# Apply clean_coordinates() to every row in tweet_coordinates column \n",
    "data[\"coordinates\"] = data.apply(clean_coordinates, args=([\"coordinates\"]), axis=1)\n",
    "\n",
    "# Create seperate columns for hashtags, user_mentions, urls, media and text variables\n",
    "data[\"hashtags\"] = \"\"\n",
    "data[\"user_mentions\"] = \"\"\n",
    "data[\"urls\"] = \"\"\n",
    "data[\"media\"] = \"\"\n",
    "data[\"cleaned_media\"] = \"\"\n",
    "data[\"has_media\"] = False\n",
    "data[\"preprocessed_text\"] = \"\"\n",
    "data[\"preprocessed_text_no_hashtag\"] = \"\"\n",
    "data[\"preprocessed_text_tokenized\"] = \"\"\n",
    "data[\"preprocessed_text_tokenized_no_hashtag\"] = \"\"\n",
    "data[\"preprocessed_text_partly\"] = \"\"\n",
    "\n",
    "data.reset_index(inplace=True, drop=True)\n",
    "\n",
    "# Convert entities column to four seperate columns (hashtags, user_mentions, urls and media)\n",
    "for i in range(len(data)):\n",
    "    entities_string = data.loc[i, 'entities']\n",
    "    \n",
    "    # Convert string to dictionary\n",
    "    entities_dict = json5.loads(entities_string)\n",
    "\n",
    "    # Convert it to multiple variables\n",
    "    data[\"hashtags\"][i] = entities_dict.get(\"hashtags\")\n",
    "    data[\"user_mentions\"][i] = entities_dict.get(\"user_mentions\")\n",
    "    data[\"urls\"][i] = entities_dict.get(\"urls\")\n",
    "    data[\"media\"][i] = entities_dict.get(\"media\")\n",
    "\n",
    "# Clean hashtags, user_mentions, urls and media fields\n",
    "data[\"hashtags\"] = data.apply(clean_field, args=([\"hashtags\", \"hashtag\"]), axis=1)\n",
    "data[\"user_mentions\"] = data.apply(clean_field, args=([\"user_mentions\", \"user_mentions\"]), axis=1)\n",
    "data[\"urls\"] = data.apply(clean_field, args=([\"urls\", \"urls\"]), axis=1)\n",
    "clean_media(data)\n",
    "\n",
    "for i in range(len(data)):\n",
    "    media = data.loc[i, 'cleaned_media']\n",
    "    \n",
    "    if media != None:\n",
    "        data.loc[i, 'has_media'] = True\n",
    "    \n",
    "# We need a variable to count the number of cases in a certain time window\n",
    "data['count'] = 1\n",
    "\n",
    "# Get the amount of words and amount of characters in a tweet\n",
    "data[\"n_words\"] = data.apply(get_n_words, args=([\"full_text\"]), axis=1)\n",
    "data[\"n_characters\"] = data.apply(get_n_characters, args=([\"full_text\"]), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What type of user that tweeted?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dataset with labelled users\n",
    "# This must be a dataframe with two columns (screen_name and type)\n",
    "labelled_users = pd.read_pickle(\"~/Documents/Github Repository/early-warning-twitter/Processed datasets/Users/01-06-2020-amsterdam-demonstration-all-interesting-users-labelled.pkl\")\n",
    "\n",
    "data[\"type_user\"] = data.apply(get_user_type, args=([\"user_screen_name\"]), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing for Text Mining\n",
    "\n",
    "Additionally, it is necessary to preprocess the text in the tweets, so that it can be analyzed for text mining."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-2-87571e3e8c1b>:287: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[\"preprocessed_text\"][i] = clean_text(text, 'keep', 'string')\n",
      "<ipython-input-2-87571e3e8c1b>:288: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[\"preprocessed_text_no_hashtag\"][i] = clean_text(text, 'lose', 'string')\n",
      "<ipython-input-2-87571e3e8c1b>:289: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[\"preprocessed_text_tokenized\"][i] = clean_text(text, 'keep', 'list')\n",
      "<ipython-input-2-87571e3e8c1b>:290: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[\"preprocessed_text_tokenized_no_hashtag\"][i] = clean_text(text, 'lose', 'list')\n",
      "<ipython-input-2-87571e3e8c1b>:411: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[\"preprocessed_text_partly\"][i] = clean_text_partly(text)\n"
     ]
    }
   ],
   "source": [
    "# Cleans the text in a tweet\n",
    "clean_full_text(data)\n",
    "\n",
    "# Partly cleans the text in a tweet\n",
    "# Necessary for back translation of the tweets\n",
    "clean_full_text_partly(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset the index\n",
    "data.reset_index(inplace=True, drop=True)\n",
    "\n",
    "#Export datasets in CSV and pickle file\n",
    "data.to_csv(\"~/Documents/Github Repository/early-warning-twitter/Processed datasets/Tweets/01-06-2020-unique-tweets-amsterdam-demonstration.csv\")\n",
    "data.to_pickle(\"~/Documents/Github Repository/early-warning-twitter/Processed datasets/Tweets/01-06-2020-unique-tweets-amsterdam-demonstration.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
