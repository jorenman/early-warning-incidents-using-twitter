{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get user information from tweets\n",
    "\n",
    "Based on a tweet dataset, we want to gather all the Twitter user information and use it in our analysis.\n",
    "The main goal of this Notebook is to get user information from users that tweeted themselves or are mentioned in tweets.\n",
    "\n",
    "In this Notebook, we will do the following:\n",
    "1. [Get the user information of every user that sent a tweet in the dataset](#section-1)\n",
    "2. [Get the user information of every mentioned user](#section-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary packages\n",
    "import pandas as pd\n",
    "\n",
    "# Import the tweet data\n",
    "data = pd.read_pickle(\"~/Documents/Github Repository/early-warning-twitter/Processed datasets/Tweets/01-06-2020-amsterdam-demonstration.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section-1\"></a>\n",
    "## 1. Get the user information of every user that sent a tweet in the dataset\n",
    "For every user that tweeted in the dataset, we will get all the user information and store it in a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy \n",
    "  \n",
    "# assign the values accordingly \n",
    "consumer_key= ''\n",
    "consumer_secret= ''\n",
    "access_token= ''\n",
    "access_token_secret= '' \n",
    "  \n",
    "# authorization of consumer key and consumer secret \n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret) \n",
    "  \n",
    "# set access to user's access key and access secret  \n",
    "auth.set_access_token(access_token, access_token_secret) \n",
    "  \n",
    "# calling the api  \n",
    "api = tweepy.API(auth, wait_on_rate_limit=True, wait_on_rate_limit_notify=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Two dataframes for storing the users\n",
    "# Users is a dataframe with Twitter users\n",
    "# not_users is a dataframe with users that are not users anymore or their account is suspended\n",
    "users = pd.DataFrame(columns = ['screen_name', 'followers_count', 'friends_count', 'listed_count', 'created_at', 'favourites_count', 'verified']) \n",
    "not_users = pd.DataFrame(columns = ['screen_name'])\n",
    "\n",
    "# Necessary to print out how many tweets we already analyzed\n",
    "tweets = 0\n",
    "tweet_benchmark = 10000\n",
    "\n",
    "# Necessary to handle the for loop\n",
    "o = 0\n",
    "l = 0\n",
    "\n",
    "# Created a list to handle the users that we already treated\n",
    "# Makes sure that if @minPres is already handled, we will not handle it again\n",
    "# We need to create a seperate list, because the API sometimes converts 'minPres' to 'minpres' (and then it is not in the dataframe)\n",
    "treated_users = []\n",
    "\n",
    "# For every mentioned user, get information of the user\n",
    "for index, screen_name in data[\"user_screen_name\"].iteritems():\n",
    "    tweets = tweets + 1\n",
    "    \n",
    "    # If 10.000 tweets have been analyzed, print out an alert\n",
    "    if(tweets > tweet_benchmark):\n",
    "        tweet_benchmark = tweet_benchmark + 10000\n",
    "        print(\"We already analyzed \"+ str(tweets) + \" tweets!\")\n",
    "    \n",
    "    # Check if tweet has user \n",
    "    if screen_name != None:\n",
    "            \n",
    "        # Check if we already treated the user\n",
    "        if not screen_name in treated_users:\n",
    "            treated_users.append(screen_name)\n",
    "                \n",
    "            try:\n",
    "                # Make API call to get user information and store it in a dataframe\n",
    "                user = api.get_user(screen_name)\n",
    "                users.loc[o,'screen_name'] = user.screen_name\n",
    "                users.loc[o, 'tweet_count'] = user.statuses_count\n",
    "                users.loc[o,'followers_count'] = user.followers_count\n",
    "                users.loc[o,'friends_count'] = user.friends_count\n",
    "                users.loc[o,'listed_count'] = user.listed_count\n",
    "                users.loc[o,'created_at'] = user.created_at\n",
    "                users.loc[o,'favourites_count'] = user.favourites_count\n",
    "                users.loc[o,'verified'] = user.verified\n",
    "                users.loc[o,'description'] = user.description\n",
    "                o = o+1   # Necessary to handle the for loop\n",
    "            except tweepy.TweepError as e:\n",
    "                # Print screen_name and error\n",
    "                print(screen_name)\n",
    "                print(e)\n",
    "                # Store screen_name in not_users dataframe\n",
    "                not_users.loc[l,'screen_name'] = screen_name\n",
    "                l = l+1\n",
    "\n",
    "# Drop duplicates in the users and non_users dataframes\n",
    "users.drop_duplicates(subset='screen_name', keep=\"first\", inplace=True)\n",
    "not_users.drop_duplicates(subset='screen_name', keep=\"first\", inplace=True)\n",
    "\n",
    "# Remove the enters from the description so that we can save the dataframe as a CSV\n",
    "users['description'] = users['description'].replace('\\n\\n',' ', regex=True) \n",
    "users['description'] = users['description'].replace('\\n',' ', regex=True)\n",
    "\n",
    "def var_to_lower(row, variable):\n",
    "    text = row[variable]\n",
    "    if type(text)==str:\n",
    "        return text.lower()\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# Make the screen_name variable lowercase\n",
    "users[\"screen_name\"] = users.apply(var_to_lower, args=([\"screen_name\"]), axis=1)\n",
    "    \n",
    "# Make description_lower variable with the description in lower case\n",
    "users[\"description_lower\"] = users.apply(var_to_lower, args=([\"description\"]), axis=1)\n",
    "\n",
    "# Reset the index of the users dataframe\n",
    "users = users.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "users.to_csv(\"~/Documents/Github Repository/early-warning-twitter/Processed datasets/Users/01-06-2020-amsterdam-demonstration-all-users-that-tweeted.csv\")\n",
    "users.to_pickle(\"~/Documents/Github Repository/early-warning-twitter/Processed datasets/Users/01-06-2020-amsterdam-demonstration-all-users-that-tweeted.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section-2\"></a>\n",
    "## 2. Get the user information of every user that is mentioned in the dataset\n",
    "For every user that is mentioned in the dataset, we will get all the user information and store it in a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Two dataframes for storing the users\n",
    "# Users is a dataframe with Twitter users\n",
    "# not_users is a dataframe with mentioned users who are actually not users or suspended users\n",
    "mentioned_users = pd.DataFrame(columns = ['screen_name', 'followers_count', 'friends_count', 'listed_count', 'created_at', 'favourites_count', 'verified']) \n",
    "mentioned_not_users = pd.DataFrame(columns = ['screen_name'])\n",
    "\n",
    "# Necessary to print out how many tweets we already analyzed\n",
    "tweets = 0\n",
    "tweet_benchmark = 10000\n",
    "\n",
    "# Necessary to handle the for loop\n",
    "o = 0\n",
    "l = 0\n",
    "\n",
    "# Created a list to handle the users that we already treated\n",
    "# Makes sure that if @minPres is already handled, we will not handle it again\n",
    "# We need to create a seperate list, because the API sometimes converts 'minPres' to 'minpres' (and then it is not in the dataframe)\n",
    "treated_users = []\n",
    "\n",
    "# For every mentioned user, get information of the user\n",
    "for index, user_mentions in data[\"user_mentions\"].iteritems():\n",
    "    tweets = tweets + 1\n",
    "    \n",
    "    # If 10.000 tweets have been analyzed, print out an alert\n",
    "    if(tweets > tweet_benchmark):\n",
    "        tweet_benchmark = tweet_benchmark + 10000\n",
    "        print(\"We already analyzed \"+ str(tweets) + \" tweets!\")\n",
    "    \n",
    "    # Check if tweet has mentioned_user\n",
    "    if user_mentions != None:\n",
    "        \n",
    "        # For every user in user_mentions\n",
    "        for screen_name in user_mentions:\n",
    "            \n",
    "            # Check if we already treated the user\n",
    "            if not screen_name in treated_users:\n",
    "                treated_users.append(screen_name)\n",
    "                \n",
    "                # Check if we already have information on the user in another DataFrame\n",
    "                if ((users['screen_name']==screen_name).any() == True):\n",
    "                    index_row = users[users['screen_name']==screen_name].index.values.astype(int)[0]\n",
    "                    mentioned_users.loc[o,'screen_name'] = users.loc[index_row,'screen_name']\n",
    "                    mentioned_users.loc[o, 'tweet_count'] = users.loc[index_row, 'tweet_count']\n",
    "                    mentioned_users.loc[o,'followers_count'] = users.loc[index_row,'followers_count']\n",
    "                    mentioned_users.loc[o,'friends_count'] = users.loc[index_row,'friends_count']\n",
    "                    mentioned_users.loc[o,'listed_count'] = users.loc[index_row,'listed_count'] \n",
    "                    mentioned_users.loc[o,'created_at'] = users.loc[index_row,'created_at']\n",
    "                    mentioned_users.loc[o,'favourites_count'] = users.loc[index_row,'favourites_count']\n",
    "                    mentioned_users.loc[o,'verified'] = users.loc[index_row,'verified']\n",
    "                    mentioned_users.loc[o,'description'] = users.loc[index_row,'description']\n",
    "                    o = o+1   # Necessary to handle the for loop\n",
    "                \n",
    "                else:\n",
    "                    try:\n",
    "                        # Make API call to get user information and store it in a dataframe\n",
    "                        user = api.get_user(screen_name)\n",
    "                        mentioned_users.loc[o,'screen_name'] = user.screen_name\n",
    "                        mentioned_users.loc[o, 'tweet_count'] = user.statuses_count\n",
    "                        mentioned_users.loc[o,'followers_count'] = user.followers_count\n",
    "                        mentioned_users.loc[o,'friends_count'] = user.friends_count\n",
    "                        mentioned_users.loc[o,'listed_count'] = user.listed_count\n",
    "                        mentioned_users.loc[o,'created_at'] = user.created_at\n",
    "                        mentioned_users.loc[o,'favourites_count'] = user.favourites_count\n",
    "                        mentioned_users.loc[o,'verified'] = user.verified\n",
    "                        mentioned_users.loc[o,'description'] = user.description\n",
    "                        o = o+1   # Necessary to handle the for loop\n",
    "                    except tweepy.TweepError as e:\n",
    "                        # Print screen_name and error\n",
    "                        print(screen_name)\n",
    "                        print(e)\n",
    "                        # Store screen_name in mentioned_not_users dataframe\n",
    "                        mentioned_not_users.loc[l,'screen_name'] = screen_name\n",
    "                        l = l+1\n",
    "\n",
    "# Drop duplicates in the users and non_users dataframes\n",
    "mentioned_users.drop_duplicates(subset='screen_name', keep=\"first\", inplace=True)\n",
    "mentioned_not_users.drop_duplicates(subset='screen_name', keep=\"first\", inplace=True)\n",
    "\n",
    "# Remove the enters from the description so that we can save the dataframe as a CSV\n",
    "mentioned_users['description'].replace('\\n\\n',' ', regex=True, inplace=True)\n",
    "mentioned_users['description'].replace('\\n',' ', regex=True, inplace=True)\n",
    "mentioned_users['description'].replace('\\r',' ', regex=True, inplace=True)\n",
    "\n",
    "def var_to_lower(row, variable):\n",
    "    desc = row[variable].lower()\n",
    "    return desc\n",
    "\n",
    "# Make screen_name variable lowercase\n",
    "mentioned_users[\"screen_name\"] = mentioned_users.apply(var_to_lower, args=([\"screen_name\"]), axis=1)\n",
    "\n",
    "# Make description_lower variable with the description in lower case\n",
    "mentioned_users[\"description_lower\"] = mentioned_users.apply(var_to_lower, args=([\"description\"]), axis=1)\n",
    "\n",
    "mentioned_users.reset_index(inplace=True, drop=True)\n",
    "\n",
    "# Export the mentioned users\n",
    "mentioned_users.to_csv(\"~/Documents/Github Repository/early-warning-twitter/Processed datasets/Users/01-06-2020-amsterdam-demonstration-all-users-that-mentioned.csv\")\n",
    "mentioned_users.to_pickle(\"~/Documents/Github Repository/early-warning-twitter/Processed datasets/Users/01-06-2020-amsterdam-demonstration-all-users-that-mentioned.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
