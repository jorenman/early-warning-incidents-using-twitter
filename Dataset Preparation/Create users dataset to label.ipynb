{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create users dataset to label\n",
    "\n",
    "The purpose of this Jupyter Notebook is to get a list of user that we can manually label.\n",
    "\n",
    "In this dataset, we will focus on four specific types of users:\n",
    "1. Users that tweeted at least 5 times\n",
    "2. Users that were mentioned at least 5 times\n",
    "3. Verified users that tweeted at least once\n",
    "4. Verified users that were mentioned at least once\n",
    "\n",
    "After we have extracted those users, we will automatically label part of the dataset.\n",
    "\n",
    "Lastly, we will import the complete labelled dataset, roll some stats and also export it to a PKL file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import all the needed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Import tweet data\n",
    "data = pd.read_pickle(\"~/Documents/Github Repository/early-warning-twitter/Processed datasets/Tweets/01-06-2020-amsterdam-demonstration.pkl\")\n",
    "\n",
    "# Import user data from users that tweeted\n",
    "tweeted_users = pd.read_pickle(\"~/Documents/Github Repository/early-warning-twitter/Processed datasets/Users/01-06-2020-amsterdam-demonstration-all-users-that-tweeted.pkl\")\n",
    "\n",
    "# Import user data from users that were mentioned in tweets\n",
    "mentioned_users = pd.read_pickle(\"~/Documents/Github Repository/early-warning-twitter/Processed datasets/Users/01-06-2020-amsterdam-demonstration-all-users-that-mentioned.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get users that tweeted at least 5 times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to count how many times a string value exists in a list\n",
    "def count_values_list(df, variable):\n",
    "    # Set counter (necessary for for-loop) and create empty dataframe\n",
    "    i = 0\n",
    "    values_df = pd.DataFrame(columns = ['value', 'count'])\n",
    "    \n",
    "    # Loop through each values element\n",
    "    for index, values in df[variable].iteritems():\n",
    "        \n",
    "        # Check if values is a string (then convert to list)\n",
    "        if type(values) == str:\n",
    "            values = values.strip('][').split(', ') \n",
    "        \n",
    "        # Check if there are any values (if list --> values available)\n",
    "        if type(values) == list:\n",
    "            \n",
    "            # Loop through all values\n",
    "            for value in values:\n",
    "                \n",
    "                value = value.lower()\n",
    "                \n",
    "                # If value is already in dataframe, add +1 to count\n",
    "                if (values_df['value']==value).any() == True:\n",
    "                    index_row = values_df[values_df['value']==value].index.values.astype(int)[0]\n",
    "                    values_df.loc[index_row, 'count'] = values_df.loc[index_row, 'count'] + 1\n",
    "                \n",
    "                # Create new value in dataframe\n",
    "                else:\n",
    "                    values_df.loc[i,'value'] = value\n",
    "                    values_df.loc[i,'count'] = 1\n",
    "                    i = i+1\n",
    "    return values_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count how many times every users has tweeted\n",
    "tweets_per_user = count_values_list(data, \"user_screen_name\")\n",
    "tweets_per_user.sort_values('count', ascending=False, inplace=True)\n",
    "tweets_per_user.rename(columns={\"value\":\"screen_name\"}, inplace=True)\n",
    "tweets_per_user_5 = tweets_per_user[tweets_per_user[\"count\"]>=5]\n",
    "\n",
    "# Export the datasets\n",
    "tweets_per_user_5.to_csv(\"~/Documents/Github Repository/early-warning-twitter/Processed datasets/Stats/01-06-2020-amsterdam-demonstration-tweets-per-user-5.csv\")\n",
    "tweets_per_user_5.to_pickle(\"~/Documents/Github Repository/early-warning-twitter/Processed datasets/Stats/01-06-2020-amsterdam-demonstration-tweets-per-user-5.pkl\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get information of users that tweeted at least 5 times\n",
    "\n",
    "# Get only the screen names of users that tweeted at least 5 times\n",
    "tweets_per_user_5_screen_name = tweets_per_user_5[[\"screen_name\"]]\n",
    "\n",
    "# Merge tweets_per_user_5 with tweeted_users\n",
    "tweets_per_user_5_user_info = pd.merge(left = tweets_per_user_5_screen_name, right=tweeted_users, left_on=\"screen_name\", right_on=\"screen_name\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get users that were mentioned at least 5 times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "mentions_count = count_values_list(data, \"user_mentions\")\n",
    "mentions_count.sort_values('count', ascending=False, inplace=True)\n",
    "mentions_count.rename(columns={\"value\":\"screen_name\"}, inplace=True)\n",
    "mentions_count_5 = mentions_count[mentions_count[\"count\"]>=5]\n",
    "\n",
    "# Export the datasets\n",
    "mentions_count_5.to_csv(\"~/Documents/Github Repository/early-warning-twitter/Processed datasets/Stats/01-06-2020-amsterdam-demonstration-mentioned-users-5.csv\")\n",
    "mentions_count_5.to_pickle(\"~/Documents/Github Repository/early-warning-twitter/Processed datasets/Stats/01-06-2020-amsterdam-demonstration-mentioned-users-5.pkl\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get information of users that were mentioned at least 5 times\n",
    "\n",
    "# Get only the screen names of users that were mentioned at least 5 times\n",
    "mentions_count_5_screen_name = mentions_count[[\"screen_name\"]]\n",
    "\n",
    "# Merge mentions_count_5 with mentioned_users dataset\n",
    "mentions_count_5_user_info = pd.merge(left = mentions_count_5, right=mentioned_users, left_on=\"screen_name\", right_on=\"screen_name\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get verified users that tweeted at least one time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweeted_verified_users = tweeted_users[tweeted_users[\"verified\"]==True][[\"screen_name\", \"description\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "73"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tweeted_verified_users)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get verified users that were mentioned at least one time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "mentioned_verified_users = mentioned_users[mentioned_users[\"verified\"]==True][[\"screen_name\", \"description\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "197"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mentioned_verified_users)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unite all four users groups in one dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate all the user\n",
    "all_interesting_users = pd.concat([tweets_per_user_5_user_info, mentions_count_5_user_info, tweeted_verified_users, mentioned_verified_users], axis=0)\n",
    "\n",
    "# Drop duplicates based on the screen name\n",
    "all_interesting_users.drop_duplicates(subset=\"screen_name\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only get the screen_name and description\n",
    "all_interesting_users = all_interesting_users[[\"screen_name\", \"description_lower\"]]\n",
    "all_interesting_users.reset_index(inplace=True, drop=True)\n",
    "\n",
    "# This results in a Dataframe with 1475 rows that need to be labelled\n",
    "all_interesting_users"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Automatically label part of the user dataset\n",
    "In this section, we will automatically label part of the user dataset by using the description of the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add type column to DataFrame\n",
    "all_interesting_users[\"type\"] = \"\"\n",
    "\n",
    "for i in range(1,len(all_interesting_users)):\n",
    "    if type(all_interesting_users.loc[i, 'description_lower']) != float:   # Check if the description is not Nan\n",
    "        if ('kamerlid' in all_interesting_users.loc[i, 'description_lower']) or ('lid tweede kamer' in all_interesting_users.loc[i, 'description_lower']) or ('member of european parliament' in all_interesting_users.loc[i, 'description_lower']) or ('member of the european parliament' in all_interesting_users.loc[i, 'description_lower']) or ('europarlementariÃ«r' in all_interesting_users.loc[i, 'description_lower']) or ('lid europees parlement' in all_interesting_users.loc[i, 'description_lower']):\n",
    "            all_interesting_users.loc[i, \"type\"] = \"Member of parliament\"\n",
    "        elif ('journalist' in all_interesting_users.loc[i, 'description_lower']) or ('nieuwschef' in all_interesting_users.loc[i, 'description_lower']) or ('verslaggever' in all_interesting_users.loc[i, 'description_lower']) or ('redacteur' in all_interesting_users.loc[i, 'description_lower']) or ('columnist' in all_interesting_users.loc[i, 'description_lower']):\n",
    "            all_interesting_users.loc[i, \"type\"] = \"Media people\"\n",
    "        elif ('politie' in all_interesting_users.loc[i, 'screen_name'].lower()):\n",
    "            all_interesting_users.loc[i, \"type\"] = \"Police\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                        1394\n",
       "Media people              67\n",
       "Member of parliament      11\n",
       "Police                     3\n",
       "Name: type, dtype: int64"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_interesting_users[\"type\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the dataset in CSV and PKL format\n",
    "all_interesting_users.to_csv(\"~/Documents/Github Repository/early-warning-twitter/Processed datasets/Users/01-06-2020-amsterdam-demonstration-all-interesting-users-partly-labelled.csv\")\n",
    "all_interesting_users.to_pickle(\"~/Documents/Github Repository/early-warning-twitter/Processed datasets/Users/01-06-2020-amsterdam-demonstration-all-interesting-users-partly-labelled.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manually label rest of the dataset\n",
    "The rest of the user dataset is manually labelled in Excel according to labelling protocol described in the thesis.\n",
    "Here we will import the dataset and also export it to a PKL file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Import complete labelled dataset\n",
    "labelled_users = pd.read_csv('~/Documents/Github Repository/early-warning-twitter/Processed datasets/Users/01-06-2020-amsterdam-demonstration-all-interesting-users-labelled.csv', sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'member of parliament' to 'politician'\n",
    "for i in range(len(labelled_users)):\n",
    "    type_user = labelled_users.loc[i, 'type']\n",
    "    \n",
    "    if(type_user == 'member of parliament'):\n",
    "        labelled_users.loc[i, 'type'] = 'politician'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "no type                            1126\n",
       "media people                        123\n",
       "politician                           95\n",
       "mass media                           52\n",
       "political party                       9\n",
       "political organization                8\n",
       "government organization               8\n",
       "police                                7\n",
       "soccer club                           7\n",
       "musician                              7\n",
       "writer                                6\n",
       "political activist                    6\n",
       "comedian                              6\n",
       "actress                               3\n",
       "municipality                          3\n",
       "mayor                                 2\n",
       "part of government organization       2\n",
       "social network                        2\n",
       "virologist                            1\n",
       "parlement                             1\n",
       "province                              1\n",
       "Name: type, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labelled_users[\"type\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the dataset\n",
    "labelled_users.to_pickle('~/Documents/Github Repository/early-warning-twitter/Processed datasets/Users/01-06-2020-amsterdam-demonstration-all-interesting-users-labelled.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
